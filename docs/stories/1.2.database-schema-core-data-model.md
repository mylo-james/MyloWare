# Story 1.2: Database Schema and Core Data Model

## Status

Complete

## Story

**As a** system architect,
**I want** a comprehensive database schema that supports all core entities,
**so that** the platform can reliably store and retrieve workflow data, memory, and audit information.

## Acceptance Criteria

1. PostgreSQL database with pgvector extension installed and configured
2. Core tables created: work_order, work_item, attempt, runs, mem_doc, approval_event, dead_letter
3. Platform tables created: connector, tool, capability, schema, workflow_template, eval_result
4. Proper indexing and foreign key constraints implemented
5. Database migration system established with version control

## Tasks / Subtasks

- [x] Task 1: Set up PostgreSQL with pgvector extension (AC: 1)
  - [x] Install and configure PostgreSQL 15.5
  - [x] Install pgvector 0.5.0 extension
  - [x] Configure database connection settings
  - [x] Set up database user and permissions
- [x] Task 2: Create core business entity tables (AC: 2)
  - [x] Create work_orders table with all required fields and indexes
  - [x] Create work_items table with foreign key to work_orders
  - [x] Create attempts table with foreign key to work_items
  - [x] Create mem_docs table with vector embedding support
  - [x] Create approval_events table with foreign key to work_items
  - [x] Create dead_letters table for failed events
- [x] Task 3: Create platform entity tables (AC: 3)
  - [x] Create connectors table for external integrations
  - [x] Create tools table with foreign key to connectors
  - [x] Create capabilities table for access control
  - [x] Create tool_capabilities junction table
  - [x] Create schemas table for document validation
  - [x] Create workflow_templates table for workflow definitions
  - [x] Create eval_results table with foreign key to work_items
- [x] Task 4: Implement database constraints and indexes (AC: 4)
  - [x] Add foreign key constraints between related tables
  - [x] Create performance optimization indexes
  - [x] Create full-text search indexes for content fields
  - [x] Add check constraints for data validation
  - [x] Create composite indexes for common query patterns
- [x] Task 5: Set up database migration system (AC: 5)
  - [x] Configure Prisma 5.7.0 ORM
  - [x] Create initial Prisma schema file
  - [x] Set up migration directory structure
  - [x] Create initial migration for all tables
  - [x] Set up database seeding script

## Dev Notes

### Previous Story Insights

This story builds on Story 1.1 which establishes the project structure. The database setup will use the Prisma configuration and Docker Compose environment established in the previous story.

### Data Models

Based on architecture data models [Source: docs/architecture/data-models.md]:

**Core Business Entities:**

- **WorkOrder**: Represents document processing requests with metadata and workflow state
- **WorkItem**: Individual documents or tasks within a work order
- **Attempt**: Tracks individual processing attempts with execution history
- **MemDoc**: Memory documents for agent context and knowledge storage
- **ApprovalEvent**: Human-in-the-loop approval decisions and governance actions
- **DeadLetter**: Failed events and messages for investigation

**Platform Entities:**

- **Connector**: External system integrations and data sources
- **Tool**: Available tools and capabilities for agents
- **Capability**: Permissions and access controls
- **Schema**: Data schemas for document types and validation
- **WorkflowTemplate**: Reusable workflow templates
- **EvalResult**: Evaluation results for quality assurance

### API Specifications

No API specifications for this story - this is database schema setup.

### Component Specifications

No UI components for this story - this is database schema setup.

### File Locations

Based on architecture source tree [Source: docs/architecture/source-tree.md]:

**Database Schema Files:**

- `prisma/schema.prisma` - Prisma schema definition
- `prisma/migrations/` - Database migrations directory
- `prisma/seed.ts` - Database seeding script

**Service Integration:**

- `packages/database-service/` - Centralized data access layer
  - `src/repositories/` - Repository implementations
  - `src/models/` - Data models
  - `src/types/` - TypeScript type definitions

### Testing Requirements

Based on architecture testing strategy [Source: docs/architecture/test-strategy-and-standards.md]:

**Database Testing:**

- Use Testcontainers PostgreSQL for integration tests
- Test all repository methods with proper mocking
- Validate foreign key constraints and data integrity
- Test migration scripts and rollback procedures
- Verify pgvector extension functionality

**Test Coverage:**

- Repository layer unit tests
- Database migration tests
- Data model validation tests
- Foreign key constraint tests

### Technical Constraints

Based on architecture tech stack [Source: docs/architecture/tech-stack.md]:

**Database:** PostgreSQL 15.5 with pgvector 0.5.0 extension
**ORM:** Prisma 5.7.0 for type-safe database access
**Vector Storage:** pgvector for embedding similarity search
**Migration Tool:** Prisma Migrate for schema versioning

**Database Extensions Required:**

- `uuid-ossp` for UUID generation
- `pgvector` for vector embeddings (1536 dimensions for OpenAI)

**Custom Types to Create:**

- `work_order_status` ENUM ('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED')
- `priority` ENUM ('LOW', 'MEDIUM', 'HIGH', 'URGENT')
- `work_item_type` ENUM ('INVOICE', 'TICKET', 'STATUS_REPORT')
- `work_item_status` ENUM ('QUEUED', 'PROCESSING', 'COMPLETED', 'FAILED')
- `attempt_status` ENUM ('STARTED', 'COMPLETED', 'FAILED', 'TIMEOUT')
- `mem_doc_type` ENUM ('CONTEXT', 'KNOWLEDGE', 'TEMPLATE')
- `approval_decision` ENUM ('APPROVED', 'REJECTED', 'ESCALATED')
- `connector_type` ENUM ('SLACK', 'EMAIL', 'API', 'DATABASE')
- `connector_status` ENUM ('ACTIVE', 'INACTIVE', 'ERROR')

### Database Schema Details

Based on architecture database schema [Source: docs/architecture/database-schema.md]:

**Core Tables Structure:**

- `work_orders`: Primary workflow orchestration table
- `work_items`: Individual document processing tasks
- `attempts`: Processing attempt tracking with agent details
- `mem_docs`: Vector-enabled memory storage
- `approval_events`: Human-in-the-loop decision tracking
- `dead_letters`: Failed event storage and recovery

**Platform Tables Structure:**

- `connectors`: External system integration configuration
- `tools`: Agent tool definitions and schemas
- `capabilities`: Access control and permissions
- `tool_capabilities`: Many-to-many relationship table
- `schemas`: Document validation schemas
- `workflow_templates`: Reusable workflow definitions
- `eval_results`: Quality assurance evaluation results

**Required Indexes:**

- Performance optimization indexes on common query patterns
- Full-text search indexes on content fields
- Vector similarity indexes on embedding fields
- Composite indexes for multi-column queries

### Environment Variables Required

- `DATABASE_URL` - PostgreSQL connection string
- `DATABASE_HOST` - Database host (default: localhost)
- `DATABASE_PORT` - Database port (default: 5432)
- `DATABASE_NAME` - Database name (default: myloware)
- `DATABASE_USER` - Database user
- `DATABASE_PASSWORD` - Database password

## Change Log

| Date       | Version | Description            | Author   |
| ---------- | ------- | ---------------------- | -------- |
| 2024-12-19 | 1.0     | Initial story creation | Bob (SM) |

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4 (Background Agent)

### Debug Log References

- Database migration created: `prisma/migrations/20241219000000_init/migration.sql`
- Prisma schema validation completed successfully
- All required tables, indexes, and constraints implemented

### Completion Notes List

1. ✅ **PostgreSQL with pgvector extension**: Configured in Docker Compose with pgvector/pgvector:pg15 image
2. ✅ **Core tables created**: All 6 core business entity tables implemented
   - work_orders: Primary workflow orchestration table with status, priority, and metadata
   - work_items: Individual document processing tasks with type and content
   - attempts: Processing attempt tracking with agent details and execution history
   - mem_docs: Vector-enabled memory storage with pgvector embedding support
   - approval_events: Human-in-the-loop decision tracking with policy versioning
   - dead_letters: Failed event storage and recovery with retry count
3. ✅ **Platform tables created**: All 7 platform entity tables implemented
   - connectors: External system integration configuration with health checks
   - tools: Agent tool definitions with JSON schemas
   - capabilities: Access control and permissions with scope-based security
   - tool_capabilities: Many-to-many relationship table for tool permissions
   - schemas: Document validation schemas with versioning
   - workflow_templates: Reusable workflow definitions with JSON workflow specs
   - eval_results: Quality assurance evaluation results with scoring
4. ✅ **Indexing and constraints**: Comprehensive indexing strategy implemented
   - Performance optimization indexes on common query patterns
   - Full-text search indexes on content fields using PostgreSQL GIN
   - Vector similarity indexes using ivfflat for embedding fields
   - Foreign key constraints with CASCADE delete for data integrity
   - Composite indexes for multi-column queries
5. ✅ **Migration system established**: Prisma-based migration system configured
   - Initial migration created with all tables, indexes, and constraints
   - Migration lock file configured for PostgreSQL
   - Database seeding script with comprehensive sample data
   - Schema validation script for testing database integrity

### File List

**Core Schema Files:**

- `prisma/schema.prisma` - Complete Prisma schema with all models and relationships
- `prisma/migrations/20241219000000_init/migration.sql` - Initial database migration
- `prisma/migrations/migration_lock.toml` - Migration provider configuration
- `prisma/seed.ts` - Database seeding script with sample data
- `.env` - Environment variables for database connection

**Support Files:**

- `scripts/validate-schema.ts` - Database schema validation and testing script
- `package.json` - Updated with Prisma dependencies and database scripts

**Database Scripts Added:**

- `npm run db:generate` - Generate Prisma client
- `npm run db:migrate` - Run database migrations
- `npm run db:seed` - Seed database with sample data
- `npm run db:validate` - Validate database schema and constraints

## QA Results

_To be populated by QA agent_
