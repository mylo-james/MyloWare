{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e61c3f",
   "metadata": {},
   "source": [
    "# Observability & Telemetry\n",
    "\n",
    "This notebook demonstrates how to use Llama Stack's telemetry for tracing and debugging workflows.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Llama Stack running at `http://localhost:5001`\n",
    "- MyloWare API running at `http://localhost:8000`\n",
    "- Jaeger or similar tracing backend (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "client = LlamaStackClient(base_url=\"http://localhost:5001\")\n",
    "API_URL = os.getenv(\"MYLOWARE_API_URL\", \"http://localhost:8000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90d303",
   "metadata": {},
   "source": [
    "## 1. Structured Logging\n",
    "\n",
    "MyloWare uses structured logging throughout the codebase:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to see MyloWare's internal operations\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Enable debug logging for specific modules\n",
    "logging.getLogger('workflows.orchestrator').setLevel(logging.DEBUG)\n",
    "logging.getLogger('tools').setLevel(logging.DEBUG)\n",
    "\n",
    "print(\"Logging configured\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10035705",
   "metadata": {},
   "source": [
    "## 2. Llama Stack Telemetry\n",
    "\n",
    "Llama Stack provides built-in telemetry for tracking agent operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75511d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example telemetry configuration for llama_stack/run.yaml:\n",
    "telemetry_config = \"\"\"\n",
    "telemetry:\n",
    "  - provider_id: otel\n",
    "    provider_type: remote::opentelemetry\n",
    "    config:\n",
    "      service_name: myloware\n",
    "      exporter_type: otlp\n",
    "      otlp_endpoint: http://localhost:4317\n",
    "\"\"\"\n",
    "print(\"Telemetry configuration example:\")\n",
    "print(telemetry_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a3544",
   "metadata": {},
   "source": [
    "## 3. Trace Correlation\n",
    "\n",
    "MyloWare correlates traces across the entire workflow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d201a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each workflow run has a unique run_id that can be traced\n",
    "print(\"Trace correlation:\")\n",
    "print(\"- run_id links all operations in a workflow\")\n",
    "print(\"- span_id identifies individual agent/tool calls\")\n",
    "print(\"- trace_id groups related runs for analysis\")\n",
    "print()\n",
    "print(\"Use Jaeger UI at http://localhost:16686 to view traces\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c440bbd",
   "metadata": {},
   "source": [
    "## 4. Key Metrics\n",
    "\n",
    "Important metrics to track for production:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Key metrics to track:\")\n",
    "metrics = [\n",
    "    \"workflow_completion_rate - % of runs that complete successfully\",\n",
    "    \"step_duration_seconds - Time spent in each workflow step\",\n",
    "    \"tool_invocation_count - Number of tool calls per run\",\n",
    "    \"tool_success_rate - % of tool calls that succeed\",\n",
    "    \"token_usage_total - Total tokens consumed per agent\",\n",
    "    \"error_rate_by_step - Error rate broken down by step type\",\n",
    "    \"external_api_latency - Response time from KIE.ai, Remotion, etc.\",\n",
    "]\n",
    "for m in metrics:\n",
    "    print(f\"  â€¢ {m}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e408ee0",
   "metadata": {},
   "source": [
    "## 5. Jaeger Setup\n",
    "\n",
    "Start Jaeger for distributed tracing:\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  -p 16686:16686 \\\n",
    "  -p 4317:4317 \\\n",
    "  jaegertracing/all-in-one:latest\n",
    "```\n",
    "\n",
    "Then configure Llama Stack telemetry to export to `localhost:4317` and open http://localhost:16686\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
